
% =============== 1. INTRODUÇÃO =======================
@article{ignacioNature,
title = {Scientists are trying to pin down how quickly climate change, deforestation and fires might ruin the world’s largest tropical rainforest},
journal = {Nature},
volume = {578},
number = {505},
year = {2020},
author = {Ignacio Amigo},
}


@Article{s20236936,
AUTHOR = {Balaniuk, Remis and Isupova, Olga and Reece, Steven},
TITLE = {Mining and Tailings Dam Detection in Satellite Imagery Using Deep Learning},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {23},
ARTICLE-NUMBER = {6936},
URL = {https://www.mdpi.com/1424-8220/20/23/6936},
ISSN = {1424-8220},
ABSTRACT = {This work explores the combination of free cloud computing, free open-source software, and deep learning methods to analyze a real, large-scale problem: the automatic country-wide identification and classification of surface mines and mining tailings dams in Brazil. Locations of officially registered mines and dams were obtained from the Brazilian government open data resource. Multispectral Sentinel-2 satellite imagery, obtained and processed at the Google Earth Engine platform, was used to train and test deep neural networks using the TensorFlow 2 application programming interface (API) and Google Colaboratory (Colab) platform. Fully convolutional neural networks were used in an innovative way to search for unregistered ore mines and tailing dams in large areas of the Brazilian territory. The efficacy of the approach is demonstrated by the discovery of 263 mines that do not have an official mining concession. This exploratory work highlights the potential of a set of new technologies, freely available, for the construction of low cost data science tools that have high social impact. At the same time, it discusses and seeks to suggest practical solutions for the complex and serious problem of illegal mining and the proliferation of tailings dams, which pose high risks to the population and the environment, especially in developing countries.},
DOI = {10.3390/s20236936}
}

@inproceedings{
  ferreira2020brazildam,
  title={BrazilDAM: A Benchmark dataset for Tailings Dam Detection},
  author={Ferreira, E., Brito, M., Alvim, M. S., Balaniuk, R., dos Santos, J.},
  booktitle={Latin American GRSS & ISPRS Remote Sensing Conference 2020, Santigo, Chile},
  year={2020},
  organization={IEEE}
}


@article{LovejoyTipping,
author = {Lovejoy, Thomas and Nobre, Carlos},
year = {2018},
month = {02},
pages = {eaat2340},
title = {Amazon Tipping Point},
volume = {4},
journal = {Science Advances},
doi = {10.1126/sciadv.aat2340}
}

@article{satyamurty2013moisture,
  title={Moisture source for the Amazon Basin: a study of contrasting years},
  author={Satyamurty, Prakki and da Costa, Claudia Priscila Wanzeler and Manzi, Antonio Ocimar},
  journal={Theoretical and Applied Climatology},
  volume={111},
  number={1},
  pages={195--209},
  year={2013},
  publisher={Springer}
}


@article{inpe_deter,
title = {METODOLOGIA DO SISTEMA DETER-B (SISTEMA DE DETECÇÃO DO DESMATAMENTO E ALTERAÇÕES NA COBERTURA FLORESTAL EM TEMPO QUASE REAL) MAPEAMENTO DE ALERTAS COM IMAGENS DOS SENSORES AWIFS-RESOURCESAT-2 E WFI-CBERS-4},
journal = {São José dos Campos},
year = {2016},
author = {Dalton de Morisson Valeriano and Igor Narvaes and Janaina Maia},
}

@misc{mapbiomasgarimpo,
  title={Nota Técnica sobre Garimpo no Rio Madeira},
  autor={Cesar Diniz and Luiz Cortinhas and  Luis Sadeck and  Pedro Walfir and  Julia Shimbo   Marcos Rosa and Tasso Azevedo},
  year={2021},
  organization = {MapBiomas}
}

@article{wang2022empirical,
  title={An Empirical Study of Remote Sensing Pretraining},
  author={Wang, Di and Zhang, Jing and Du, Bo and Xia, Gui-Song and Tao, Dacheng},
  journal={arXiv preprint arXiv:2204.02825},
  year={2022}
}

@article{alom2018history,
  title={The history began from alexnet: A comprehensive survey on deep learning approaches},
  author={Alom, Md Zahangir and Taha, Tarek M and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Van Esesn, Brian C and Awwal, Abdul A S and Asari, Vijayan K},
  journal={arXiv preprint arXiv:1803.01164},
  year={2018}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{kattenborn2021review,
  title={Review on Convolutional Neural Networks (CNN) in vegetation remote sensing},
  author={Kattenborn, Teja and Leitloff, Jens and Schiefer, Felix and Hinz, Stefan},
  journal={ISPRS Journal of Photogrammetry and Remote Sensing},
  volume={173},
  pages={24--49},
  year={2021},
  publisher={Elsevier}
}

@ARTICLE{5782957,
  author={Sedaghat, Amin and Mokhtarzade, Mehdi and Ebadi, Hamid},
  journal={IEEE Transactions on Geoscience and Remote Sensing},
  title={Uniform Robust Scale-Invariant Feature Matching for Optical Remote Sensing Images},
  year={2011},
  volume={49},
  number={11},
  pages={4516-4527},
  doi={10.1109/TGRS.2011.2144607}}



  @article{ABIODUN2018e00938,
title = {State-of-the-art in artificial neural network applications: A survey},
journal = {Heliyon},
volume = {4},
number = {11},
pages = {e00938},
year = {2018},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2018.e00938},
url = {https://www.sciencedirect.com/science/article/pii/S2405844018332067},
author = {Oludare Isaac Abiodun and Aman Jantan and Abiodun Esther Omolara and Kemi Victoria Dada and Nachaat AbdElatif Mohamed and Humaira Arshad},
keywords = {Computer science},
abstract = {This is a survey of neural network applications in the real-world scenario. It provides a taxonomy of artificial neural networks (ANNs) and furnish the reader with knowledge of current and emerging trends in ANN applications research and area of focus for researchers. Additionally, the study presents ANN application challenges, contributions, compare performances and critiques methods. The study covers many applications of ANN techniques in various disciplines which include computing, science, engineering, medicine, environmental, agriculture, mining, technology, climate, business, arts, and nanotechnology, etc. The study assesses ANN contributions, compare performances and critiques methods. The study found that neural-network models such as feedforward and feedback propagation artificial neural networks are performing better in its application to human problems. Therefore, we proposed feedforward and feedback propagation ANN models for research focus based on data analysis factors like accuracy, processing speed, latency, fault tolerance, volume, scalability, convergence, and performance. Moreover, we recommend that instead of applying a single method, future research can focus on combining ANN models into one network-wide application.}
}



% =============== 2. REFERÊNCIA BIBLIOGRÁFICA =======================


@book{emery2017introduction,
  title={Introduction to Satellite Remote Sensing: Atmosphere, Ocean, Land and Cryosphere Applications},
  author={Emery, B. and Camps, A. and Rodriguez-Cassola, M.},
  isbn={9780128092590},
  lccn={2018286240},
  url={https://books.google.com.br/books?id=sZLUDQAAQBAJ},
  year={2017},
  publisher={Elsevier Science}
}

@misc{InstrutorGIS,
  title={QGIS: Satélite Amazonia-1 – Composição Colorida RGB},
  url={https://www.instrutorgis.com.br/qgis-satelite-amazonia1-composicao-colorida-rgb},
  journal={instrutorgis},
  author={instrutorgis},
  year={2022},
  volume={3}
}

@article{Samuel1959SomeSI,
  title={Some Studies in Machine Learning Using the Game of Checkers},
  author={Arthur L. Samuel},
  journal={IBM J. Res. Dev.},
  year={1959},
  volume={3},
  pages={210-229}
}

@book{Mitchell97,
  abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. This exciting addition to the McGraw-Hill Series in Computer Science focuses on the concepts and techniques that contribute to the rapidly changing field of machine learning---including probability and statistics, artificial intelligence, and neural networks---unifying them all in a logical and coherent manner.},
  added-at = {2017-05-08T14:37:30.000+0200},
  address = {New York},
  author = {Mitchell, Tom M.},
  biburl = {https://www.bibsonomy.org/bibtex/23e79734ee1a6e49aee02ffd108224d1c/flint63},
  file = {eBook:1900-99/Mitchell97.pdf:PDF;McGraw-Hill Product page:http\://www.mhprofessional.com/product.php?isbn=0070428077:URL;Amazon Search inside:http\://www.amazon.de/gp/reader/0070428077/:URL},
  groups = {public},
  interhash = {479a66c32badb3a455fbdcf8e6633a5d},
  intrahash = {3e79734ee1a6e49aee02ffd108224d1c},
  isbn = {978-0-07-042807-2},
  keywords = {01624 105 book shelf ai learn algorithm},
  publisher = {McGraw-Hill},
  timestamp = {2017-07-13T17:10:10.000+0200},
  title = {Machine Learning},
  username = {flint63},
  year = 1997
}

@Book{GoodBengCour16,
  Title                    = {Deep Learning},
  Author                   = {Ian J. Goodfellow and Yoshua Bengio and Aaron Courville},
  Publisher                = {MIT Press},
  Year                     = {2016},
  Address                  = {Cambridge, MA, USA},
  Note                     = {\url{http://www.deeplearningbook.org}}
}


@book{hastie01statisticallearning,
  added-at = {2008-05-16T16:17:42.000+0200},
  address = {New York, NY, USA},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  interhash = {d585aea274f2b9b228fc1629bc273644},
  intrahash = {f58afc5c9793fcc8ad8389824e57984c},
  keywords = {ml statistics},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  timestamp = {2008-05-16T16:17:43.000+0200},
  title = {The Elements of Statistical Learning},
  year = 2001
}


@book{PDLT-2022,
    title = "The Principles of Deep Learning Theory",
    author = "Roberts, Daniel A. and Yaida, Sho and Hanin, Boris",
    publisher = "Cambridge University Press",
    year = "2022",
    eprint = "2106.10165",
    archivePrefix = "arXiv",
    primaryClass = "cs.LG",
    note={\url{https://deeplearningtheory.com}},
}


@INPROCEEDINGS{8308186,
  author={Albawi, Saad and Mohammed, Tareq Abed and Al-Zawi, Saad},
  booktitle={2017 International Conference on Engineering and Technology (ICET)},
  title={Understanding of a convolutional neural network},
  year={2017},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ICEngTechnol.2017.8308186}}



@misc{AttentionIsAllYouNeed,
  doi = {10.48550/ARXIV.1706.03762},
  url = {https://arxiv.org/abs/1706.03762},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Attention Is All You Need},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@phdthesis{rostami2019learning,
  title={Learning Transferable Knowledge Through Embedding Spaces},
  author={Rostami, Mohammad},
  year={2019},
  school={University of Pennsylvania}
}



@MastersThesis{Sanches2003,
  Title = {Aprendizado de Máquina Semi-supervisionado: Proposta de um Algoritmo para Rotular Exemplos a Partir de Poucos Exemplos Rotulados},
  Author = {Marcelo Kaminski Sanches},
  School = {Universidade de São Paulo},
  Year = {2003},
  Url = {http://www.teses.usp.br/teses/disponiveis/55/55134/tde-12092003-101358}
}



@misc{ViTvsResNets,
  doi = {10.48550/ARXIV.2106.01548},
    url = {https://arxiv.org/abs/2106.01548},
    author = {Chen, Xiangning and Hsieh, Cho-Jui and Gong, Boqing},
    keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {When Vision Transformers Outperform ResNets without Pre-training or Strong Data Augmentations},
    publisher = {arXiv},
    year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}




% Trabalhos parecidos
@Article{rs14071746,
AUTHOR = {Camalan, Seda and Cui, Kangning and Pauca, Victor Paul and Alqahtani, Sarra and Silman, Miles and Chan, Raymond and Plemmons, Robert Jame and Dethier, Evan Nylen and Fernandez, Luis E. and Lutz, David A.},
TITLE = {Change Detection of Amazonian Alluvial Gold Mining Using Deep Learning and Sentinel-2 Imagery},
JOURNAL = {Remote Sensing},
VOLUME = {14},
YEAR = {2022},
NUMBER = {7},
ARTICLE-NUMBER = {1746},
URL = {https://www.mdpi.com/2072-4292/14/7/1746},
ISSN = {2072-4292},
ABSTRACT = {Monitoring changes within the land surface and open water bodies is critical for natural resource management, conservation, and environmental policy. While the use of satellite imagery for these purposes is common, fine-scale change detection can be a technical challenge. Difficulties arise from variable atmospheric conditions and the problem of assigning pixels to individual objects. We examined the degree to which two machine learning approaches can better characterize change detection in the context of a current conservation challenge, artisanal small-scale gold mining (ASGM). We obtained Sentinel-2 imagery and consulted with domain experts to construct an open-source labeled land-cover change dataset. The focus of this dataset is the Madre de Dios (MDD) region in Peru, a hotspot of ASGM activity. We also generated datasets of active ASGM areas in other countries (Venezuela, Indonesia, and Myanmar) for out-of-sample testing. With these labeled data, we utilized a supervised (E-ReCNN) and semi-supervised (SVM-STV) approach to study binary and multi-class change within mining ponds in the MDD region. Additionally, we tested how the inclusion of multiple channels, histogram matching, and La*b* color metrics improved the performance of the models and reduced the influence of atmospheric effects. Empirical results show that the supervised E-ReCNN method on 6-Channel histogram-matched images generated the most accurate detection of change not only in the focal region (Kappa: 0.92 (&plusmn; 0.04), Jaccard: 0.88 (&plusmn; 0.07), F1: 0.88 (&plusmn; 0.05)) but also in the out-of-sample prediction regions (Kappa: 0.90 (&plusmn; 0.03), Jaccard: 0.84 (&plusmn; 0.04), and F1: 0.77 (&plusmn; 0.04)). While semi-supervised methods did not perform as accurately on 6- or 10-channel imagery, histogram matching and the inclusion of La*b* metrics generated accurate results with low memory and resource costs. These results show that E-ReCNN is capable of accurately detecting specific and object-oriented environmental changes related to ASGM. E-ReCNN is scalable to areas outside the focal area and is a method of change detection that can be extended to other forms of land-use modification.},
DOI = {10.3390/rs14071746}
}


@ARTICLE{9701667,
  author={Kaselimi, Maria and Voulodimos, Athanasios and Daskalopoulos, Ioannis and Doulamis, Nikolaos and Doulamis, Anastasios},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Vision Transformer Model for Convolution-Free Multilabel Classification of Satellite Imagery in Deforestation Monitoring}, 
  year={2022},
  volume={},
  number={},
  pages={1-9},
  abstract={Understanding the dynamics of deforestation and land uses of neighboring areas is of vital importance for the design and development of appropriate forest conservation and management policies. In this article, we approach deforestation as a multilabel classification (MLC) problem in an endeavor to capture the various relevant land uses from satellite images. To this end, we propose a multilabel vision transformer model, ForestViT, which leverages the benefits of the self-attention mechanism, obviating any convolution operations involved in commonly used deep learning models utilized for deforestation detection. Experimental evaluation in open satellite imagery datasets yields promising results in the case of MLC, particularly for imbalanced classes, and indicates ForestViT's superiority compared with well-established convolutional structures (ResNET, VGG, DenseNet, and ModileNet neural networks). This superiority is more evident for minority classes.},
  keywords={},
  doi={10.1109/TNNLS.2022.3144791},
  ISSN={2162-2388},
  month={},}

@misc{https://doi.org/10.48550/arxiv.2003.07948,
  doi = {10.48550/ARXIV.2003.07948},
  url = {https://arxiv.org/abs/2003.07948},
  author = {Ferreira, Edemir and Brito, Matheus and Balaniuk, Remis and Alvim, Mário S. and Santos, Jefersson A. dos},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {BrazilDAM: A Benchmark dataset for Tailings Dam Detection},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{liu2022swin,
author = {Liu, Ze and Hu, Han and Lin, Yutong and Yao, Zhuliang and Xie, Zhenda and Wei, Yixuan and Ning, Jia and Cao, Yue and Zhang, Zheng and Dong, Li and Wei, Furu and Guo, Baining},
title = {Swin Transformer V2: Scaling Up Capacity and Resolution},
booktitle = {CVPR 2022},
year = {2022},
month = {May},
abstract = {Large-scale NLP models have been shown to significantly improve the performance on language tasks with no signs of saturation. They also demonstrate amazing few-shot capabilities like that of human beings. This paper aims to explore large-scale models in computer vision. We tackle three major issues in training and application of large vision models, including training instability, resolution gaps between pre-training and fine-tuning, and hunger on labelled data. Three main techniques are proposed: 1) a residual-post-norm method combined with cosine attention to improve training stability; 2) A log-spaced continuous position bias method to effectively transfer models pre-trained using low-resolution images to downstream tasks with high-resolution inputs; 3) A self-supervised pre-training method, SimMIM, to reduce the needs of vast labeled images. Through these techniques, this paper successfully trained a 3 billion-parameter Swin Transformer V2 model, which is the largest dense vision model to date, and makes it capable of training with images of up to 1,536×1,536 resolution. It set new performance records on 4 representative vision tasks, including ImageNet-V2 image classification, COCO object detection, ADE20K semantic segmentation, and Kinetics-400 video action classification. Also note our training is much more efficient than that in Google's billion-level visual models, which consumes 40 times less labelled data and 40 times less training time.},
url = {https://www.microsoft.com/en-us/research/publication/swin-transformer-v2-scaling-up-capacity-and-resolution/},
}

@misc{https://doi.org/10.48550/arxiv.1512.03385,
  doi = {10.48550/ARXIV.1512.03385},
  url = {https://arxiv.org/abs/1512.03385},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Residual Learning for Image Recognition},
  publisher = {arXiv},
  year = {2015},  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


@misc{torchvision.models.swin_t,
  doi = {torchvision.models.swin_t},
  url = {https://pytorch.org/vision/main/models/generated/torchvision.models.swin_t.html},
    keywords = {Pytorch Models},
  title = {torchvision.models.swin_t}
}

@article{https://doi.org/10.48550/arxiv.2106.10270,
  doi = {10.48550/ARXIV.2106.10270},
  url = {https://arxiv.org/abs/2106.10270},
  author = {Steiner, Andreas and Kolesnikov, Alexander and Zhai, Xiaohua and Wightman, Ross and Uszkoreit, Jakob and Beyer, Lucas},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers},
  publisher = {arXiv},
  year = {2021},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
